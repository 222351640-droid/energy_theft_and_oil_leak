{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5a7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading energy data...\n",
      "✅ Data loaded successfully!\n",
      "\n",
      "Creating features for anomaly detection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6083/2918710316.py:59: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ).fillna(method='bfill').fillna(method='ffill')\n",
      "/tmp/ipykernel_6083/2918710316.py:66: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  energy_df['pct_change'] = energy_df.groupby('CONS_NO')['consumption'].transform('pct_change').fillna(0)\n",
      "/tmp/ipykernel_6083/2918710316.py:72: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ).fillna(method='bfill')\n",
      "/tmp/ipykernel_6083/2918710316.py:76: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ).fillna(method='bfill')\n",
      "/tmp/ipykernel_6083/2918710316.py:89: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  energy_df = energy_df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Isolation Forest model...\n",
      "\n",
      "Consumers with highest anomaly percentages:\n",
      "                            CONS_NO  predicted_anomaly  anomaly_percentage\n",
      "0  0000E78A22CB04533A0D9E1F2FBEEC5D                  0                 NaN\n",
      "1  0002D8E9C198E4A2B03BFA6D1E2E1B6D                  0                 NaN\n",
      "2  000395F84A94D4CB2E5D4D77372CFB4D                  0                 NaN\n",
      "3  000E6116D092E1C94AF3EFA5998363B0                  0                 NaN\n",
      "4  00127DCB5EB56E6D3C56E88CE5816CBE                  0                 NaN\n",
      "\n",
      "Saving results to both data directories...\n",
      "✅ Saved energy_features.csv to both data directories\n",
      "✅ Saved energy_model.joblib to both data directories\n",
      "✅ Saved energy_scaler.joblib to both data directories\n",
      "\n",
      "✅ All files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 04_model_energy_theft.ipynb\n",
    "# AI Model for Energy Theft Detection\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1️⃣ Import Libraries\n",
    "# ---------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2️⃣ Set up directories\n",
    "# ---------------------------------------------------\n",
    "# Create all necessary directories\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SRC_DATA_DIR = Path.cwd().parent / 'src' / 'data'\n",
    "SRC_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Function to save to both data directories\n",
    "def save_to_both_locations(filename, obj, is_dataframe=True):\n",
    "    if is_dataframe:\n",
    "        obj.to_csv(DATA_DIR / filename, index=False)\n",
    "        obj.to_csv(SRC_DATA_DIR / filename, index=False)\n",
    "    else:\n",
    "        joblib.dump(obj, DATA_DIR / filename)\n",
    "        joblib.dump(obj, SRC_DATA_DIR / filename)\n",
    "    print(f\"✅ Saved {filename} to both data directories\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3️⃣ Load and Prepare Data\n",
    "# ---------------------------------------------------\n",
    "energy_path = DATA_DIR / 'energy_data_transformed.csv'\n",
    "\n",
    "print(\"Loading energy data...\")\n",
    "energy_df = pd.read_csv(energy_path)\n",
    "energy_df['date'] = pd.to_datetime(energy_df['date'])\n",
    "print(\"✅ Data loaded successfully!\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3️⃣ Create Features\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nCreating features for anomaly detection...\")\n",
    "\n",
    "# Sort by consumer and date to ensure correct feature calculation\n",
    "energy_df = energy_df.sort_values(['CONS_NO', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Rolling statistics (with handling for edge cases)\n",
    "energy_df['rolling_mean_3'] = energy_df.groupby('CONS_NO')['consumption'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    ").fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "energy_df['rolling_std_3'] = energy_df.groupby('CONS_NO')['consumption'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).std()\n",
    ").fillna(0)  # Fill NaN with 0 for std when there's not enough data\n",
    "\n",
    "# Percentage change (capped at ±100% to handle extreme values)\n",
    "energy_df['pct_change'] = energy_df.groupby('CONS_NO')['consumption'].transform('pct_change').fillna(0)\n",
    "energy_df['pct_change'] = energy_df['pct_change'].clip(-1, 1)  # Cap at ±100%\n",
    "\n",
    "# Lagged values\n",
    "energy_df['lag_1'] = energy_df.groupby('CONS_NO')['consumption'].transform(\n",
    "    lambda x: x.shift(1)\n",
    ").fillna(method='bfill')\n",
    "\n",
    "energy_df['lag_2'] = energy_df.groupby('CONS_NO')['consumption'].transform(\n",
    "    lambda x: x.shift(2)\n",
    ").fillna(method='bfill')\n",
    "\n",
    "# Z-score within each consumer's data (with handling for edge cases)\n",
    "def safe_zscore(x):\n",
    "    std = x.std()\n",
    "    if std == 0:\n",
    "        return np.zeros_like(x)\n",
    "    return (x - x.mean()) / std\n",
    "\n",
    "energy_df['z_score'] = energy_df.groupby('CONS_NO')['consumption'].transform(safe_zscore)\n",
    "\n",
    "# Replace any remaining infinities with large finite values\n",
    "energy_df = energy_df.replace([np.inf, -np.inf], np.nan)\n",
    "energy_df = energy_df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4️⃣ Prepare Data for Modeling\n",
    "# ---------------------------------------------------\n",
    "# Select features for anomaly detection\n",
    "features = ['consumption', 'rolling_mean_3', 'rolling_std_3', 'pct_change', \n",
    "           'lag_1', 'lag_2', 'z_score']\n",
    "X = energy_df[features]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5️⃣ Train Isolation Forest\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nTraining Isolation Forest model...\")\n",
    "iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
    "energy_df['anomaly_score'] = iso_forest.fit_predict(X_scaled)\n",
    "\n",
    "# Label anomalies: -1 → anomaly, 1 → normal\n",
    "energy_df['predicted_anomaly'] = energy_df['anomaly_score'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6️⃣ Analyze Results\n",
    "# ---------------------------------------------------\n",
    "# Count anomalies per consumer\n",
    "anomaly_counts = energy_df.groupby('CONS_NO')['predicted_anomaly'].sum().reset_index()\n",
    "anomaly_counts['anomaly_percentage'] = (anomaly_counts['predicted_anomaly'] / \n",
    "                                      energy_df.groupby('CONS_NO').size() * 100)\n",
    "\n",
    "print(\"\\nConsumers with highest anomaly percentages:\")\n",
    "print(anomaly_counts.sort_values('anomaly_percentage', ascending=False).head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7️⃣ Save Results to Both Locations\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nSaving results to both data directories...\")\n",
    "# Save the engineered features\n",
    "save_to_both_locations('energy_features.csv', energy_df, is_dataframe=True)\n",
    "\n",
    "# Save the model and scaler\n",
    "save_to_both_locations('energy_model.joblib', iso_forest, is_dataframe=False)\n",
    "save_to_both_locations('energy_scaler.joblib', scaler, is_dataframe=False)\n",
    "\n",
    "print(\"\\n✅ All files saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
